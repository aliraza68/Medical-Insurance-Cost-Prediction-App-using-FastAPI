# importing necessary libraries
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns

# Linear Regression
from sklearn.linear_model import LinearRegression

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score,mean_squared_error

# RandomForest Regression
from sklearn.ensemble import RandomForestRegressor


print(f"Installed numpy version: {np.__version__}")
print(f"Installed pandas version: {pd.__version__}")
print(f"Installed matplotlib version: {matplotlib.__version__}")
print(f"Installed seaborn version: {sns.__version__}")





df = pd.read_csv('data/insurance.csv')

df.head(10)


print("Total no of samples in dataset:", df.shape)


print("Information about dataset features and data-type")
df.info()


# No missing and NaN values
df.describe()


# check the null values
df.isnull().sum()


# No of unique values in categorical columns
print("Unique values in sex column:", df['sex'].unique())
print("Unique values in children column:", df['children'].unique())
print("Unique values in smoker column:", df['smoker'].unique())
print("Unique values in region column:", df['region'].unique())





# Encoding categorical columns
from sklearn.preprocessing import LabelEncoder

# sex column (Male: 1, Fenale: 0)
le = LabelEncoder()
le.fit( df['sex'].drop_duplicates() )
df['sex'] = le.transform(df['sex'])


print("Learned classes in sex column")
le.classes_


df.head(3)


# patient is smoker or not
le.fit( df['smoker'].drop_duplicates() ) 

# Yes: 1, No: 0
df['smoker'] = le.transform( df['smoker'] )


le.classes_


df.head(3)


# region column
le.fit( df['region'].drop_duplicates() )

df['region'] = le.transform( df['region'] )


# 0 for 'northeast', 1 for 'northwest', 2 for 'southeast', 3 for 'southwest'
le.classes_


df.head(3)


# finding the correlation
df.corr()['charges'].sort_values(ascending = False)


# using heatmap
corr_values = df.corr()
sns.heatmap(data = corr_values, square = True,annot = True, fmt = ".2f")

plt.show()


# knowing more about data
sns.displot(df["charges"])

plt.show()


smoker_patients = df[df['smoker'] == 1]
non_smoker_patients = df[df['smoker'] == 0]

f= plt.figure(figsize=(12,5))

ax = f.add_subplot(121)
sns.distplot(smoker_patients["charges"], color = 'c', ax = ax)
ax.set_title('Distribution of charges for smokers')

ax=f.add_subplot(122)
sns.distplot(non_smoker_patients['charges'], color = 'b', ax = ax)
ax.set_title('Distribution of charges for non-smokers')

plt.show()


# finding no of smoker and non-smokers

# Here, in legend: 0 shows femal, and 1 shows male candidates
sns.catplot(data= df, x = "smoker", kind = "count", hue = "sex")

plt.show()


# box plots for charges
# extract women insurance data
female_data = df[ df["sex"] == 0]

plt.figure(figsize = (12,5))
sns.boxplot(data = female_data, x = "charges", y = "smoker", orient = 'h')

plt.title("Box plot for charges of women candidates")
plt.show()


# box plots for charges
# extract men insurance data
men_data = df[ df["sex"] == 1]

plt.figure(figsize = (12,5))
sns.boxplot(data = men_data, x = "charges", y = "smoker", orient = 'h')

plt.title("Box plot for charges of men candidates")
plt.show()


# let's pay attention to the age of the patients
plt.figure(figsize = (8,5))
ax = sns.displot(df["age"], kind = 'hist', color = 'g')
plt.title("Distribution of age")

plt.show()


patient_18_to_20 = df[ (df['age'] >= 18) & (df['age'] <=20) ]

# Here in legend: 0 shows female patients, and 1 shows male
sns.catplot(data = patient_18_to_20, x = "smoker", kind = "count", 
            hue = "sex", palette = "rainbow")

plt.show()


patient_18_to_20 = df[ (df['age'] >= 18) & (df['age'] <=20) ]

plt.figure(figsize = (12,5))
sns.boxplot(data = patient_18_to_20, x = "charges", y = "smoker",
            orient = "h")

plt.title("Box plot for charges 18 years old smokers")


# let explore no of childrens
sns.catplot(data = df, x = "children", kind = "count")

plt.show()


plt.figure(figsize = (12, 6))

sns.boxplot(data = df, x = "charges", y = "children", orient = "h")

plt.title("Distribution of chagres with patient children count")
plt.show()


plt.figure(figsize = (12, 6))
sns.boxplot(data = df, x = "charges", y = "children", hue = "smoker",
            orient = "h")

plt.title("Distribution of chagres with patient children count")
plt.show()


df.head(3)


# Here I want to clear some thing
# ---- In sex column: 0 shows female patient and 1 for male patient
# ----- In smoker column: 0 shows non-smoker, and 1 shows patient is smoker
# ----- In region column: values are from 0 to 3 w.r.t to index value of list below
# ['northeast', 'northwest', 'southeast', 'southwest']


x = df.drop(['charges'], axis = 1)
y = df['charges']


# features (X) set
x.head(3)


y.head(3)


# data preparsion for model training
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, 
                                                    random_state = 42)


print("shape of train set", x_train.shape)
print("Shape of test set", x_test.shape)


# Model 1: Linear Regression
lr = LinearRegression()
lr.fit(x_train, y_train)


# make prediction
y_train_pred = lr.predict(x_train)
y_test_pred = lr.predict(x_test)


# comparing 
print("Actual values from test set:\n", np.array(y_test[:10]))
print("Predicted values from test set:\n", np.array(y_test_pred[:10]))


print(f"MSE train data: {mean_squared_error(y_train, y_train_pred)}")
print(f"MSE test data: {mean_squared_error(y_test, y_test_pred)}")

print(f"R2 Score train data: {r2_score(y_train, y_train_pred)}")
print(f"R2 Score test data: {r2_score(y_test, y_test_pred)}")



# result analysis
plt.figure(figsize = (10,6))

# scatter of train-data predictions
plt.scatter(y_train_pred, y_train_pred - y_train, c = 'black', 
           marker = 'o', s = 35, alpha = 0.5, label = 'Train data')

# scatter of test-data predictions
plt.scatter(y_test_pred, y_test_pred - y_test, c = 'c', 
           marker = 'o', s = 35, alpha = 0.7, label = 'Test data')

# add horizental line (red colour)
plt.hlines(y = 0, xmin = 0, xmax = 60000, lw = 2, color = 'red')

plt.title("[Linear Regression] Charges prediction away from actual values")

plt.xlabel('Predicted values')
plt.ylabel('Tailings')
plt.legend(loc = 'upper left')


plt.show()


# Model 2: RandomForest Regressor
rf_reg = RandomForestRegressor(n_estimators = 150,
                              criterion = 'squared_error',
                              random_state = 42,
                              n_jobs = -1)

rf_reg.fit(x_train, y_train)
rf_train_pred = rf_reg.predict(x_train)
rf_test_pred = rf_reg.predict(x_test)


print(f"[RandomForest] MSE train data: {mean_squared_error(y_train, rf_train_pred)}")
print(f"[RandomForest] MSE test data: {mean_squared_error(y_test, rf_test_pred)}")

print(f"[RandomForest] R2 Score train data: {r2_score(y_train, rf_train_pred)}")
print(f"[RandomForest] R2 Score test data: {r2_score(y_test, rf_test_pred)}")


# result analysis
plt.figure(figsize = (10,6))

# scatter of train-data predictions
plt.scatter(rf_train_pred, rf_train_pred - y_train, c = 'black', 
           marker = 'o', s = 35, alpha = 0.5, label = 'Train data')

# scatter of test-data predictions
plt.scatter(rf_test_pred, rf_test_pred - y_test, c = 'c', 
           marker = 'o', s = 35, alpha = 0.7, label = 'Test data')

# add horizental line (red colour)
plt.hlines(y = 0, xmin = 0, xmax = 60000, lw = 2, color = 'red')

plt.title("[RandomForest Regressor] Charges prediction away from actual values")

plt.xlabel('Predicted values')
plt.ylabel('Tailings')
plt.legend(loc = 'upper left')


plt.show()


# save the random Forest model
import pickle

pickle_model_path = "model.pkl"
with open(pickle_model_path, 'wb') as f:
    pickle.dump(rf_reg, f)

print("Model saved successfully")



