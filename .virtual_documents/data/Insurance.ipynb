# importing necessary libraries
import numpy as np
import pandas as pd
import matplotlib
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.metrics import classification_report, accuracy_score


# show version
print(f"installed numpy version: {np.__version__}")
print(f"installed pandas version: {pd.__version__}")
print(f"installed matplotlib version: {matplotlib.__version__}")
print(f"installed Seaborn version: {sns.__version__}")


# Load the dataset
insurance_df = pd.read_csv("data/new_insurance.csv")


insurance_df.head()


insurance_df.info()


insurance_df.describe()


# view random samples
insurance_df.sample(5)


# finding no of unique values
print("Unique values in smoker column")
insurance_df["smoker"].unique()


unique_cities = list(insurance_df["city"].unique() )

print("UNique cities",unique_cities)
print(f"Total no of unique cities: {len(unique_cities)}")


unique_occupations = list(insurance_df["occupation"].unique() )

print("Unique occupation",unique_occupations)
print(f"Total no of unique occupation: {len(unique_occupations)}")


# get unique values in target column (insurance_premium_category)
unique_premium_categories = list(insurance_df["insurance_premium_category"].unique() )

print("Unique Premium categories",unique_premium_categories)
print(f"Total no of unique Premium Categories: {len(unique_premium_categories)}")


# Data Exploration and Analysis
insurance_df["insurance_premium_category"].value_counts().plot(kind = "bar")

plt.title("Distribution of Premium Category")
plt.xlabel("Premium Category")
plt.ylabel("Count")

plt.show()


# no of insurance users from each city
insurance_df["city"].value_counts().plot(kind = "bar")

plt.title("Insurance members from each city")
plt.ylabel("Count")

plt.show()


# Insurance policy (High, Medium, Low) offered to types of occupation of users

sns.countplot(data= insurance_df, x = "insurance_premium_category", hue = "occupation")

plt.title("Type of Insurance offered to various Occupation")

plt.xlabel("Insurance Premium Category")
plt.ylabel("Count")

plt.show()





# Feature 1: Calculating BMI of the user
value = insurance_df["weight"] / (insurance_df["height"] ** 2)
value[:10]


insurance_df["bmi"] = insurance_df["weight"] / (insurance_df["height"] ** 2)


insurance_df.head()


# Feature 2: Categorizing user age into group
# Group Name: Young, Adult, Middle-Aged, Senior
def age_group(age):
    if age < 25:
        return "young"
    
    elif age < 45:
        return "adult"
    
    elif age < 60:
        return "middle_aged"
    
    return "senior"

#test
print(age_group(60))
print(age_group(30))
print(age_group(10))


# applying age_group method to each column value
insurance_df["age_group"] = insurance_df["age"].apply( age_group )


insurance_df.head()


# Feature 3: Creating a Lifestyle Risk column, which depends on two features: Smoker, bmi
# these two features plays a critical role to determining a life-sttyle risk oa any user (patient)
def lifestyle_risk(row):
    # if smoker user has high bmi value -> risk hight 
    if (row["smoker"]) and (row["bmi"] > 30):
        return "high"
    
    # high bmi value of a non smoker has medium risk factor
    elif (row["smoker"]) or (row["bmi"] > 27):
        return "medium"
        
    else:
        return "low"



insurance_df.apply( lifestyle_risk, axis = 1 ).value_counts()


insurance_df["life_style_risk"] = insurance_df.apply( lifestyle_risk, axis = 1 )


insurance_df.head()


tier_1_cities = ["Mumbai", "Delhi", "Bangalore", "Chennai", "Kolkata", "Hyderabad", "Pune"]
tier_2_cities = [
    "Jaipur", "Chandigarh", "Indore", "Lucknow", "Patna", "Ranchi", "Visakhapatnam", "Coimbatore",
    "Bhopal", "Nagpur", "Vadodara", "Surat", "Rajkot", "Jodhpur", "Raipur", "Amritsar", "Varanasi",
    "Agra", "Dehradun", "Mysore", "Jabalpur", "Guwahati", "Thiruvananthapuram", "Ludhiana", "Nashik",
    "Allahabad", "Udaipur", "Aurangabad", "Hubli", "Belgaum", "Salem", "Vijayawada", "Tiruchirappalli",
    "Bhavnagar", "Gwalior", "Dhanbad", "Bareilly", "Aligarh", "Gaya", "Kozhikode", "Warangal",
    "Kolhapur", "Bilaspur", "Jalandhar", "Noida", "Guntur", "Asansol", "Siliguri"
]


# Feature 4: groups of cities
def city_tier(city):
    if city in tier_1_cities:
        return 1
        
    elif city in tier_2_cities:
        return 2
        
    else:
        return 3


# applying method to each column value
insurance_df["city"].apply( city_tier ).value_counts()  


insurance_df["city_tier"] = insurance_df["city"].apply( city_tier )


insurance_df.head()


# selecing only engineered features
cols_to_select = ["bmi", "age_group", "life_style_risk", "city_tier", "income_lpa", "occupation", "insurance_premium_category"]
insurance_df[cols_to_select].sample(5)


# select featurs and target
features = ["bmi", "age_group", "life_style_risk", "city_tier", "income_lpa", "occupation"]
target = ["insurance_premium_category"]
X = insurance_df[features]
y = insurance_df[target]


print( X.head() )

print(y.head())


# Define categorical and numeric features (X)
categorical_features = ["age_group", "life_style_risk", "occupation", "city_tier"]
numeric_features = ["bmi", "income_lpa"]
     


# Create column transformer for OHE transformation
preprocessor = ColumnTransformer(
    transformers = [
        ("cat", OneHotEncoder(), categorical_features),
        ("num", "passthrough", numeric_features)
    ]
)


# Create a pipeline with preprocessing and random forest classifier
pipeline = Pipeline(steps = [
    ("preprocessor", preprocessor),
    ("classifier", RandomForestClassifier(n_estimators = 150, random_state = 42))
])


# Split data and train model
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)



np.array(y_train)[:, 0]


pipeline.fit(X_train, np.array(y_train)[:, 0])


# Predict and evaluate
y_pred = pipeline.predict(X_test)
accuracy_score(y_test, y_pred)












